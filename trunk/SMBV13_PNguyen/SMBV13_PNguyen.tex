%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Dokument-Einstellungen
\documentclass{SMBV13}

\setcounter{tocdepth}{5} %to make it appears in TOC
\setcounter{secnumdepth}{5} %to make it numbered

\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}[section]
%\usepackage{algorithm}
%\usepackage{algpseudocode}
%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------
% Hier beginnt das eigentliche Dokument
\begin{document}

\title{Graph-Based Segmentation}

\author{Phan-Anh Nguyen}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------% Zusammenfassung

\begin{abstract}%
The purpose of image segmentation is to partition an image into meaningful regions with respect to a particular application. Segmentation is commonly used in medical image processing to locate tumors, measure tissue volumes and to study anatomical structure. Segmentation is also a crucial part in scene understanding for autonomous systems. However there are several issues often encountered during segmentation. First, the object we want to detect does not always have the same shape. This can cause troubles for the segmentation methods that depend on pre-defined shapes. Secondly, there are no clear boundaries between objects and background due to image clutters and noises. This seminar paper reviews three novel graph-based approaches to the image segmentation problem. The first approach builds a region graph to detect object as the optimal subgraph weighted by a support vector machine classifier applied to bag-of-features regions. The second approach identifies salient contours within an image by solving an Hermitian eigenvalue problem on a contour grouping graph. The third approach extends the min-cut algorithm to solve the multi-class segmentation problem on a Markov random field. Pros and cons and some comparisons between these graph-cut methods are discussed at the end of the present seminar paper.
\end{abstract}

\keywords{Classification, Graph-Cut, Segmentation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------
%
\section{Introduction}

Image segmentation is an initial and vital step in the whole image processing pipeline aimed at overall image understanding. Segmentation is often used to identify objects in a scene for object-based measurements such as size and shape. This is particularly useful for computer-aided diagnosis applications which assist physicians in finding abnormalities based on medical images of patients. Segmentation is also used to identify obstacles in depth images taken from a mobile robot to generate the optimal path. There are two main problems that prohibit the segmentation task from delivering good results. First, the object we want to detect does not always have the same shape. This can cause troubles for the segmentation methods that depend on pre-defined shapes. Secondly, there are no clear boundaries between objects and background due to image clutters and noises.

Graph-based segmentation is currently emerging as a promising method and has been applied successfully to many image processing applications ranging from scene understanding and segmentation to medical image analysis. Formulating segmentation problems by means of graph theory has a twofold advantage: Firstly, graph representation is an abstract way to encode generic complex relationships between entities, thereby opening up to a wide variety of interpretations for the segmentation problems provided that they can define some metrics to measure the relationships; Secondly, graph representation often leads to well-known graph problems which have been studied for a while and therefore can be solved efficiently.

In general, a graph-based segmentation method often follows the following pipeline. First, image features, which are signal responses from some filters describing important image properties, are extracted from an input image. These features serve as numerical elements used to construct a graph often based on supervised learning algorithms. Once we have built a graph to represent the image segmentation problem, we can apply state-of-the-art graph-cut algorithms to solve the problem efficiently. 

Beside graph-based approaches, a wide variety of segmentation methods have been proposed. Mortensen et al. \cite{mortensen1995intelligent} introduced an interactive segmentation system in which an user picks up some seed points to define a contour that can automatically snap around the object of interest. The system used the Dijkstra's shortest path algorithm to find the lowest cost path in a cost image which is defined based on gradient. Chan and Vese proposed a segmentation method called ``Active contours without edges'' \cite{chan2001active} which used level set formulation to model the evolution of boundaries under internal and external forces. The system did not use gradient for stopping condition thereby being able to identify objects that are very smooth, or even have discontinous boundaries. The system proposed by Fripp et al. \cite{fripp2007automatic} uses three-dimensional active shape models to segment cartilages and rebuild a 3D-model of them. The reconstruction error is below 1 mm.

This seminar paper presents several different graph-based approaches to the image segmentation problem and demonstrates some applications of these techniques to real-world problems. Particularly, Section $\ref{sec:features}$ describes several methods to extract features from images notably Speeded Up Robust Features (SURF) \cite{bay2006surf} is used to describe local image information around a feature point as well as a shape descriptor \cite{gu2009recognition} based on the Globalized Probability of Boundary (gPb) \cite{martin2004learning} \cite{maire2008using}. Section $\ref{sec:supervised_learning}$ introduces some supervised learning techniques which are used in Section $\ref{sec:graph_cunstruction}$ to construct a graph. Section $\ref{sec:graph_cut_algorithms}$ presents powerful graph-cut algorithms used to select optimal subgraphs as segmentation solutions. The applications of graph-cut algorithms to solve the segmentation problem are illustrated in Section $\ref{sec:applications}$ in three different systems namely ``Efficient Region Search'' \cite{VijayGrauman2011} to search for an object of arbitrary shape, ``Contour Cut'' \cite{KenGalShi2011} to identify salient contours in images and ``Multi-Shape Graph-Cut'' \cite{nakagomimulti} to perform lung segmentation based on multiple shape priors. Finally, Section $\ref{sec:conclusion}$ discusses advantages and disadvantages and gives some comparisons between these graph-cut methods.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------
%
\section{Image Features}
\label{sec:features}
Low level image features are essential building blocks for high level image processing tasks such as object detection, image categorization or segmentation. In general, image features capture important properties around local image regions in the form of high dimensional feature vectors that can be used by high level applications. The advantage of the compact representation of features is that it can be readily fed into standard algorithms which often take high dimensional vectors as input. Also features are often made to be invariant to different transformations e.g. rotation, scaling etc. Since features are defined locally, they are invariant to translation. To support real-time systems features need to be efficient to compute. Normally, raw features are extracted at each pixel by applying various kinds of filters. Each filter response corresponds to one dimension in the feature vector space. The shape and size of filters reflect local structure around each pixel. Raw features at each pixel can be collected to form region descriptors which can be used to represent shapes, contours etc. In this section, we present methods to extract raw features and various ways of constructing region descriptors. Specifically, Section $\ref{sec:surf}$ describes a state-of-the-art feature named Speeded Up Robust Features (SURF) \cite{bay2006surf} and Section $\ref{sec:shape_feature}$ explains the Globalized Probability of Boundary (gPb) contour detector \cite{maire2008using}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Speeded Up Robust Features}
\label{sec:surf}
Speeded Up Robust Features (SURF) \cite{bay2006surf} was originally developed for the task of finding point correspondences between two images of the same scene. This includes three main steps. First, interest points are selected at distinctive locations in the image. Then a feature vector is extracted from the neighbourhood of every interest point. Finally, the feature vectors are matched between different images. Since the SURF descriptor provides a very good representation of a local region it has also been applied to tasks other than correspondence problems such as image classification or image segmentation.

Regarding the interest point detection problem the choice of a detector varies depending on the needs of the application. An application for image registration requires the same interest points to be detected in two different images of the same scene under different viewing conditions. In this case, a detector would pick up hard-to-miss points which appear in both images such as peaks in signal responses corresponding to blobs or corners. In the case of image segmentation it would be a wise choice to select points on contours to be interest points. In the original SURF paper Bay et al. suggested to use an approximate Hessian detector to search in scale-space domain for points having strong derivatives in two orthogonal directions as interest points (often located at corners and strongly textured areas).

Given an interest point in the input image the SURF descriptor is obtained by extracting distinctive information around its neighborhood in a form of a feature vector. The SURF descriptor is designed to be invariant to image scaling and rotation while it can be computed very fast. Scale invariance is achieved by adopting the scale at which the Hessian detector attains maximal response. In order to be invariant to rotation we first find a reproducible orientation based on information within a circular region around the interest point. We then construct a square region aligned to the selected orientation and extract the SURF descriptor from it.

To find the dominant orientation Haar wavelet responses in $x$ and $y$ directions ($d_x$, $d_y$) are calculated within a circular neighbourhood of radius $6s$ around the interest point and weighted with a Gaussian ($\sigma = 2s$), where $s$ is the scale chosen above. Figure $\ref{fig:haar_wavelet}$ shows the structure of the Haar wavelet filters. The wavelet responses ($d_x, d_y$) are then represented in a vector space and the sum of all vectors within a sliding orientation window of size $\frac{\pi}{3}$ is calculated, see Figure $\ref{fig:orientation_window}$. The dominant orientation is finally assigned to the sum vector having the maximal length.

\begin{figure}[htbp]
    \centering
    \subfigure[]
    {
        \includegraphics[width=0.15\textwidth]{Bilder/SMBV13_EMuster_fig1}
        \label{fig:haar_wavelet}
    }
    \subfigure[]
    {
        \includegraphics[width=0.25\textwidth]{Bilder/SMBV13_EMuster_fig2}
        \label{fig:orientation_window}
    }
    \subfigure[]
    {
        \includegraphics[width=0.5\textwidth]{Bilder/SMBV13_EMuster_fig3}
        \label{fig:surf}
    }
    \caption{(a) Haar wavelet filters for the x (left) and y (right) components. The dark parts are weighted -1 and the light parts +1. (b) Orientation assignment: A sliding orientation window of size $\frac{\pi}{3}$ detects the dominant orientation. (c) The SURF descriptor: An oriented quadratic grid with $4 \times 4$ square cells is laid over the interest point (left). For each cell, the wavelet responses are computed from $5 \times 5$ samples (for illustrative purposes, only $2 \times 2$ sub-divisions are shown here). In each cell, the 4 elements $\sum d_x$, $\sum \left| d_x \right|$, $\sum d_y$, $\sum \left| d_y \right| $ contribute to the SURF feature vector. The images are taken from \cite{bay2006surf}.} 
    %\label{fig:surf}
\end{figure}

To extract the SURF descriptor, we construct a window of size $20s$ centred at the interest point and oriented in the dominant orientation as illustrated in Figure $\ref{fig:surf}$. The window is then subdivided into regular $4 \times 4$ grid cells, each being a $5 \times 5$ pixel patch. For each cell, the Gaussian weighted ($\sigma = 3.3s$) Haar wavelet responses are summed up to form a first set of entries in the feature vector. The sum of the absolute values of the responses, $\left| d_x \right| $ and $\left| d_y \right| $ are also extracted to capture information about the polarity of the intensity changes. Therefore, each cell has a 4D descriptor vector for its underlying intensity structure $\left( \sum d_x, \sum d_y, \sum \left| d_x \right| , \sum \left| d_y \right|  \right)$. Concatenating this for all $4 \times 4$ cells results in a descriptor vector of length 64. Finally the descriptor vector is normalized to make it invariant to contrast.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Globalized Probability of Boundary}
\label{sec:shape_feature}

The globalized probability of boundary (gPb) contour extractor was developed based on the predecessor, namely probability of boundary (Pb), which uses features extracted from a local image patch to estimate the posterior probability of a boundary passing through the current pixel. gPb improves from Pb by introducing global information based on spectral graph theory. In this section we will first survey the local features used by Pb. We will then explain how gPb incorporates global information into Pb. Finally, we will show one method to extract shape descriptors from regions defined by gPb contours. The method to estimate the posterior probability of a boundary will be explained in more detail in Section $\ref{sec:logistic_regression}$.


\subsubsection{Gradient-Based Features for Probability of Boundary}
\label{sec:textons}

The gradient-based paradigm was used by Martin et al. in their $Pb$ paper \cite{martin2004learning} to detect local changes in color, texture and brightness. The algorithm to compute the probability of boundary based on brightness and color features proceeds with the following steps:
\begin{enumerate}
\item At each pixel location $(x, y)$, a circle of radius $r$ is drawn and cut half along the diameter having orientation $\theta$.
\item Histograms of color and brightness in the CIELAB color space \footnote{The CIELAB color space has three dimensions. The L* axis represents lightness ranging from 0 for black to 100 for white. The a* axis is green at one extremity (represented by -a), and red at the other (+a). The b* axis has blue at one end (-b), and yellow (+b) at the other. The color range is between -128 and +127.} are built for each half disk. The L* channel is used to compute the brightness histogram and the a* and b* channels are used to compute the color histogram. 
\item Let $h(x, y, \theta, r)$ and $g(x, y, \theta, r)$ denote the histograms of the two disk halves. We define the gradient function $G(x, y, \theta, r)$ which is the $\chi^2$ distance between the histograms $h$ and $g$:
\begin{equation}
	\chi^2(g, h) = \frac{1}{2} \sum \dfrac{(g_i - h_i)^2}{g_i + h_i}
\end{equation}
\item An edge is detected if there is a large difference $G(x, y, \theta, r)$ between the two half disks along the chosen orientation.
\item A supervised learning method is used to combine the cues into a single detector. This produces soft boundary maps of the form $Pb(x, y, \theta)$.
\end{enumerate}   

\begin{figure}[htbp]
    \centering
    %\subfigure[]
    %{
    %    \includegraphics[width=0.2\textwidth]{images/kde.png}
    %    \label{fig:kde}
    %}
    \subfigure[]
    {
        \includegraphics[width=0.1\textwidth]{Bilder/SMBV13_EMuster_fig4}
        \label{fig:filter_bank}
    }
    \subfigure[]
    {
        \includegraphics[width=0.3\textwidth]{Bilder/SMBV13_EMuster_fig5}
        \label{fig:textons}
    }
    \subfigure[]
    {
        \includegraphics[width=0.5\textwidth]{Bilder/SMBV13_EMuster_fig6}
        \label{fig:texture_map}
    }
    \caption{(a) Filter Bank: The 13-element filter bank used for computing textons. (b) Universal Textons: Example universal textons computed from the 200 training images, sorted by L1 norm for display purposes. (c) Texton Map: An image and its associated texton map. The images are taken from \cite{martin2004learning}.} 
    %\label{fig:texture}
\end{figure}

The same algorithm is used to compute texture gradient but the technique to calculate the texture histogram is different. Specifically, a group of 13 filters covering the most probable shapes is used. It consists of six pairs of elongated, oriented filters and a center-surround filter as shown in Figure $\ref{fig:filter_bank}$. The oriented filters are in even/odd quadrature pairs. The even symmetric filter is a Gaussian second derivative, and the odd-symmetric filter is its Hilbert transform. Finally, a difference of Gaussians is chosen to be the center-surround filter. This filter bank generates a feature vector of 13 dimensions corresponding to 13 filter responses at each pixel.

In order to build up histograms for comparison the $Pb$ algorithm uses the so called textons approach (or bag-of-textures approach) introduced by Malik et al. \cite{malik2001contour}. The basic idea is to cluster the filter response vectors over a large diverse collection of training images using k-means. Each cluster defines a Voronoi cell in the space of joint filter responses and the cluster centers, textons, represent texture primitives. Figure $\ref{fig:textons}$ illustrates example textons for k = 64 computed over the 200 images in the training set. Once the dictionary of textons has been computed each pixel is assigned to the nearest texton. Figure $\ref{fig:texture_map}$ shows an image and the associated texton map, where each pixel has been labeled with the nearest texton. Finally, the histograms of activated textons in the two disc halves can be computed and compared using the $\chi^2$ distance operator.























%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------
%
\def\refname{Literatur}
\begin{thebibliography}{AA}
                 
\bibitem{mortensen1995intelligent} Mortensen, Eric N., and William A. Barrett: Intelligent scissors for image composition. Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. ACM, 1995.

\bibitem{fripp2007automatic} Fripp, Jurgen and Crozier, Stuart and Warfield, Simon and Ourselin, S{\'e}bastien: Automatic segmentation of articular cartilage in magnetic resonance images of the knee. Medical Image Computing and Computer-Assisted Intervention--MICCAI 2007 (2007): 186--194.

\bibitem{chan2001active} Chan, Tony F and Vese, Luminita A: Active contours without edges. Image Processing, IEEE Transactions on 10.2 (2001): 266--277.

\bibitem{nowozin2009global} Nowozin, Sebastian, and Christoph H. Lampert: Global connectivity potentials for random field models. Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009.

\bibitem{gleich2006hierarchical} Gleich, David: Hierarchical directed spectral graph partitioning. (2006).

\bibitem{lempitsky2010fusion} Lempitsky, Victor, Carsten Rother, Stefan Roth, and Andrew Blake: Fusion moves for markov random field optimization. Pattern Analysis and Machine Intelligence, IEEE Transactions on 32, no. 8 (2010): 1392--1405.

\bibitem{kolmogorov2007minimizing} Kolmogorov, Vladimir, and Carsten Rother: Minimizing nonsubmodular functions with graph cuts-a review. Pattern Analysis and Machine Intelligence, IEEE Transactions on 29.7 (2007): 1274--1279.

\bibitem{boykov2004experimental} Boykov, Yuri, and Vladimir Kolmogorov: An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision. Pattern Analysis and Machine Intelligence, IEEE Transactions on 26.9 (2004): 1124--1137.

\bibitem{mitchell2002branch} Mitchell, John E: Branch-and-cut algorithms for combinatorial optimization problems. Handbook of Applied Optimization (2002): 65--77.

\bibitem{VijayGrauman2011} Vijayanarasimhan, Sudheendra, and Kristen Grauman: Efficient region search for object detection. Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE, 2011.

\bibitem{bishop2006pattern} Bishop, Christopher M.: Pattern recognition and machine learning. Vol. 4. No. 4. New York: springer, 2006.

\bibitem{shimizu2011automated} Shimizu, Akinobu, Keita Nakagomi, Takuya Narihira, Hidefumi Kobatake, Shigeru Nawano, Kenji Shinozaki, Koich Ishizu, and Kaori Togashi: Automated segmentation of 3D CT images based on statistical atlas and graph cuts. Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging (2011): 214--223.

\bibitem{KenGalShi2011} Kennedy, Ryan, Jean Gallier, and Jianbo Shi: Contour cut: identifying salient contours in images by solving a Hermitian eigenvalue problem. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pp. 2065--2072. IEEE, 2011.

\bibitem{nakagomimulti} Nakagomi, Keita, Akinobu Shimizu, Hidefumi Kobatake, Masahiro Yakami, Koji Fujimoto, and Kaori Togashi: Multi-shape graph-cuts and its application to lung segmentation from a chest CT volume.

\bibitem{leventon2000statistical} Leventon, Michael E., W. Eric L. Grimson, and Olivier Faugeras: Statistical shape influence in geodesic active contours. In Computer Vision and Pattern Recognition, 2000. Proceedings. IEEE Conference on, vol. 1, pp. 316--323. IEEE, 2000.

\bibitem{tsochantaridis2006large} Tsochantaridis, Ioannis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun: Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research 6, no. 2 (2006): 1453.

\bibitem{maire2008using} Maire, M. and Arbel{\'a}ez, P. and Fowlkes, C. and Malik, J.: Using contours to detect and localize junctions in natural images. In Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, pp. 1--8. IEEE, 2008.

\bibitem{gu2009recognition} Gu, C. and Lim, J.J. and Arbel{\'a}ez, P. and Malik, J.: Recognition using regions. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 1030--1037. IEEE, 2009.

\bibitem{bay2006surf} Bay, Herbert, Tinne Tuytelaars, and Luc Van Gool: Surf: Speeded up robust features. Computer Vision--ECCV 2006 (2006): 404--417.

\bibitem{ljubic2006algorithmic} Ljubi{\'c}, I. and Weiskircher, R. and Pferschy, U. and Klau, G.W. and Mutzel, P. and Fischetti, M.: An algorithmic framework for the exact solution of the prize--collecting Steiner tree problem. Mathematical Programming 105, no. 2 (2006): 427--449.

\bibitem{shi2000normalized} Shi, Jianbo, and Jitendra Malik: Normalized cuts and image segmentation. Pattern Analysis and Machine Intelligence, IEEE Transactions on 22, no. 8 (2000): 888--905.

\bibitem{zhu2007untangling} Zhu, Qihui, Gang Song, and Jianbo Shi: Untangling cycles for contour grouping. In Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pp. 1--8. IEEE, 2007.

\bibitem{martin2004learning} Martin, David R., Charless C. Fowlkes, and Jitendra Malik: Learning to detect natural image boundaries using local brightness, color, and texture cues. Pattern Analysis and Machine Intelligence, IEEE Transactions on 26, no. 5 (2004): 530--549.

\bibitem{arbelaez2009contours} Arbel{\'a}ez, P. and Maire, M. and Fowlkes, C. and Malik, J.: From contours to regions: An empirical evaluation. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp. 2294--2301. IEEE, 2009.

\bibitem{malik2001contour} Malik, Jitendra, Serge Belongie, Thomas Leung, and Jianbo Shi: Contour and texture analysis for image segmentation. International Journal of Computer Vision 43, no. 1 (2001): 7--27.

\bibitem{leung1998contour} Leung, Thomas, and Jitendra Malik: Contour continuity in region based image segmentation. Computer Vision--ECCV'98 (1998): 544--559.

\bibitem{cortes1995support} Cortes, Corinna, and Vladimir Vapnik: Support--vector networks. Machine learning 20, no. 3 (1995): 273--297.

\bibitem{burges1998tutorial} Burges, Christopher JC: A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery 2, no. 2 (1998): 121--167.

\bibitem{lampert2008beyond} Lampert, Christoph H., Matthew B. Blaschko, and Thomas Hofmann: Beyond sliding windows: Object localization by efficient subwindow search. In Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, pp. 1--8. IEEE, 2008.

\end{thebibliography}

%\noindent
%\begin{picture}(160,242)
%\put(0,0){\framebox(160,242){}}
%\end{picture}

\end{document}
